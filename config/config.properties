# Inference API binding address. Default: http://127.0.0.1:8080
inference_address=http://0.0.0.0:8080
# Management API binding address. Default: http://127.0.0.1:8081
management_address=http://0.0.0.0:8081
# Metrics API binding address. Default: http://127.0.0.1:8082
metrics_address=http://0.0.0.0:8082
# Maximum number of GPUs that TorchServe can use for inference. Default: all available GPUs in system, if the value is larger than the GPU number torchserve will adjust it to real GPU number
# number_of_gpu=10